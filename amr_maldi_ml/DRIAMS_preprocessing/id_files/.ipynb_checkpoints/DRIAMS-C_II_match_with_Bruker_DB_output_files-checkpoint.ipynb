{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from collections import defaultdict as ddict\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_KSA_FOLDER = '/links/groups/borgwardt/Data/ms_diagnostics/validation/Aarau/'\n",
    "PATH_FILE_spectra_filelist = PATH_KSA_FOLDER + 'files_position.csv'\n",
    "PATH_to_Bruker_output = PATH_KSA_FOLDER + 'splits/result_files/'\n",
    "PATH_FILE_lab_file = PATH_KSA_FOLDER + 'raw/Keime_AB_0101-3108_2018_anonymised.csv'\n",
    "PATH_FILE_ab_matching = PATH_KSA_FOLDER + '../AB-matching.csv'\n",
    "\n",
    "OUTPUT_FILE = '/links/groups/borgwardt/Data/DRIAMS/DRIAMS-C/id/2018_clean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits = 15\n",
    "\n",
    "# (1) match list of spectra files with Bruker output files\n",
    "# (2) match that with lab results, take only cases where (LabID, species) is unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# replace Umlaute in Aarau script, as this will cause problems later on\n",
    "#sed -i 's/Ã¤/ae/g' /links/groups/borgwardt/Data/ms_diagnostics/validation/Aarau/raw/Keime_AB_0101-3108_2018_anonymised.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO change name matching to general script, not from AB-matching.csv\n",
    "def get_antibiotics_name_matching(match_from='LIESTAL', match_to='USB'):\n",
    "    assert match_from in ['LIESTAL','USB','Viollier','Aarau','Madrid']\n",
    "    assert match_to in ['LIESTAL','USB','Viollier','Aarau','Madrid']\n",
    "    csvname = '/links/groups/borgwardt/Projects/maldi_tof_diagnostics/amr_maldi_ml/MaldiML/MaldiML/files/AB-matching.csv'\n",
    "\n",
    "    with open(csvname,'r', encoding='mac_roman') as f:\n",
    "        ff = csv.reader(f, delimiter=',', dialect=csv.excel)\n",
    "        list_antibiotics = []\n",
    "\n",
    "        d_naming = ddict(list)\n",
    "\n",
    "        for j, row in enumerate(ff):\n",
    "\n",
    "            if j==0:\n",
    "                inidx = row.index(match_from)\n",
    "                outidx = row.index(match_to)\n",
    "            else:\n",
    "                inname = row[inidx]\n",
    "                outname = row[outidx]\n",
    "                if inname == '':\n",
    "                    continue\n",
    "                else:\n",
    "                    d_naming[inname] = outname\n",
    "    return d_naming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) match list of spectra files with output from Bruker report files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read-in list of files\n",
    "for k in range(num_splits):\n",
    "    \n",
    "    # read-in filelist_split files\n",
    "    locals()['filelist_split{}'.format(k)] = pd.read_csv(PATH_KSA_FOLDER+'splits/filelist_files/filelist_split{}.csv'.format(k), sep=';', header=None)\n",
    "    split_file = locals()['filelist_split{}'.format(k)]\n",
    "    split_file = split_file.iloc[:,9:]\n",
    "    split_file.columns = ['Jahr', 'Datum_Kuerzel', 'LaborID', 'Position']\n",
    "\n",
    "    # check that Tagesnr column has unique entries\n",
    "    assert len(split_file.LaborID) == len(np.unique(split_file.LaborID))\n",
    "\n",
    "    locals()['filelist_split{}'.format(k)] = split_file\n",
    "    assert id(split_file) == id(locals()['filelist_split{}'.format(k)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7862\n"
     ]
    }
   ],
   "source": [
    "# how many samples were distributed into the splitfiles\n",
    "n_sampl = 0\n",
    "for k in range(num_splits):\n",
    "    n_sampl+= len(locals()['filelist_split{}'.format(k)])\n",
    "print(n_sampl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of BrukerID entries 7845\n"
     ]
    }
   ],
   "source": [
    "# read-in reports\n",
    "n_BrukerID = 0\n",
    "for k in range(num_splits):\n",
    "    report = pd.read_csv(PATH_to_Bruker_output+'results_split_{}.csv'.format(k), sep=';', header=None)\n",
    "    n_BrukerID += len(report)\n",
    "    \n",
    "    report.columns = ['LaborID', 'Value','A','Organism_best_match', 'Score1', 'Organism_second_best_match', 'Score2','empty']\n",
    "    report.drop(['empty'], axis=1, inplace=True)\n",
    "    \n",
    "    # check that LaborID column has unique entries\n",
    "    assert len(report.LaborID) == len(np.unique(report.LaborID))\n",
    "    locals()['report_{}'.format(k)] = report\n",
    "\n",
    "print('Number of BrukerID entries {}'.format(n_BrukerID))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number entries before clean-up: 3033\n",
      "number entries after clean-up: 2782\n",
      "\n",
      "number entries before clean-up: 1976\n",
      "number entries after clean-up: 1809\n",
      "\n",
      "number entries before clean-up: 1156\n",
      "number entries after clean-up: 1008\n",
      "\n",
      "number entries before clean-up: 671\n",
      "number entries after clean-up: 581\n",
      "\n",
      "number entries before clean-up: 387\n",
      "number entries after clean-up: 321\n",
      "\n",
      "number entries before clean-up: 242\n",
      "number entries after clean-up: 194\n",
      "\n",
      "number entries before clean-up: 150\n",
      "number entries after clean-up: 115\n",
      "\n",
      "number entries before clean-up: 93\n",
      "number entries after clean-up: 78\n",
      "\n",
      "number entries before clean-up: 58\n",
      "number entries after clean-up: 42\n",
      "\n",
      "number entries before clean-up: 37\n",
      "number entries after clean-up: 25\n",
      "\n",
      "number entries before clean-up: 20\n",
      "number entries after clean-up: 16\n",
      "\n",
      "number entries before clean-up: 15\n",
      "number entries after clean-up: 12\n",
      "\n",
      "number entries before clean-up: 10\n",
      "number entries after clean-up: 8\n",
      "\n",
      "number entries before clean-up: 7\n",
      "number entries after clean-up: 5\n",
      "\n",
      "number entries before clean-up: 7\n",
      "number entries after clean-up: 7\n",
      "\n",
      "total number of spectra lost to clean up: 859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join both tables, clean up for bad Bruker results\n",
    "n_reduce_all = 0\n",
    "\n",
    "for k in range(num_splits):  \n",
    "    report = locals()['report_{}'.format(k)]\n",
    "    filelist = locals()['filelist_split{}'.format(k)]\n",
    "    \n",
    "    spectra_to_species = filelist.set_index('LaborID').join(report.set_index('LaborID'))\n",
    "    \n",
    "    # clean up\n",
    "    n_reduce = len(spectra_to_species)\n",
    "    print('number entries before clean-up: {}'.format(len(spectra_to_species)))\n",
    "    spectra_to_species = spectra_to_species[spectra_to_species.Organism_best_match != 'not reliable identification']\n",
    "    spectra_to_species = spectra_to_species[spectra_to_species.Organism_second_best_match != 'not reliable identification']\n",
    "    spectra_to_species = spectra_to_species[~spectra_to_species.Organism_best_match.isnull()]\n",
    "    spectra_to_species = spectra_to_species[~spectra_to_species.Organism_best_match.str.startswith('MIX')]\n",
    "    spectra_to_species = spectra_to_species[spectra_to_species.Organism_best_match != 'no peaks found']\n",
    "    \n",
    "    print('number entries after clean-up: {}\\n'.format(len(spectra_to_species)))\n",
    "    n_reduce -= len(spectra_to_species)\n",
    "    n_reduce_all += n_reduce   \n",
    "    locals()['spectra_to_species_{}'.format(k)] = spectra_to_species\n",
    "\n",
    "print('total number of spectra lost to clean up: {}\\n'.format(n_reduce_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7003\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jahr</th>\n",
       "      <th>Datum_Kuerzel</th>\n",
       "      <th>Position</th>\n",
       "      <th>Value</th>\n",
       "      <th>A</th>\n",
       "      <th>Organism_best_match</th>\n",
       "      <th>Score1</th>\n",
       "      <th>Organism_second_best_match</th>\n",
       "      <th>Score2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LaborID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2806190738</th>\n",
       "      <td>2018</td>\n",
       "      <td>20180620_rm</td>\n",
       "      <td>0_A4</td>\n",
       "      <td>( +++ )</td>\n",
       "      <td>( B )</td>\n",
       "      <td>Enterobacter cloacae</td>\n",
       "      <td>2.41</td>\n",
       "      <td>Enterobacter cloacae</td>\n",
       "      <td>2.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806191053</th>\n",
       "      <td>2018</td>\n",
       "      <td>20180620_rm</td>\n",
       "      <td>0_B5</td>\n",
       "      <td>( ++ )</td>\n",
       "      <td>( A )</td>\n",
       "      <td>Staphylococcus aureus</td>\n",
       "      <td>2.27</td>\n",
       "      <td>Staphylococcus aureus</td>\n",
       "      <td>2.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806180958</th>\n",
       "      <td>2018</td>\n",
       "      <td>20180620_rm</td>\n",
       "      <td>0_C9</td>\n",
       "      <td>( ++ )</td>\n",
       "      <td>( A )</td>\n",
       "      <td>Candida tropicalis</td>\n",
       "      <td>2</td>\n",
       "      <td>Candida tropicalis</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806191010</th>\n",
       "      <td>2018</td>\n",
       "      <td>20180620_rm</td>\n",
       "      <td>0_B4</td>\n",
       "      <td>( +++ )</td>\n",
       "      <td>( C )</td>\n",
       "      <td>Klebsiella oxytoca</td>\n",
       "      <td>2.32</td>\n",
       "      <td>Klebsiella oxytoca</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806180419</th>\n",
       "      <td>2018</td>\n",
       "      <td>20180620_rm</td>\n",
       "      <td>0_C3</td>\n",
       "      <td>( ++ )</td>\n",
       "      <td>( A )</td>\n",
       "      <td>Lautropia mirabilis</td>\n",
       "      <td>2.07</td>\n",
       "      <td>Lautropia mirabilis</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Jahr Datum_Kuerzel Position    Value      A  \\\n",
       "LaborID                                                   \n",
       "2806190738  2018   20180620_rm     0_A4  ( +++ )  ( B )   \n",
       "2806191053  2018   20180620_rm     0_B5   ( ++ )  ( A )   \n",
       "2806180958  2018   20180620_rm     0_C9   ( ++ )  ( A )   \n",
       "2806191010  2018   20180620_rm     0_B4  ( +++ )  ( C )   \n",
       "2806180419  2018   20180620_rm     0_C3   ( ++ )  ( A )   \n",
       "\n",
       "              Organism_best_match Score1 Organism_second_best_match Score2  \n",
       "LaborID                                                                     \n",
       "2806190738   Enterobacter cloacae   2.41       Enterobacter cloacae   2.26  \n",
       "2806191053  Staphylococcus aureus   2.27      Staphylococcus aureus   2.23  \n",
       "2806180958     Candida tropicalis      2         Candida tropicalis   1.98  \n",
       "2806191010     Klebsiella oxytoca   2.32         Klebsiella oxytoca   2.31  \n",
       "2806180419    Lautropia mirabilis   2.07        Lautropia mirabilis   2.06  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine to one spectra_to_species DataFrame\n",
    "spectra_to_species = spectra_to_species_0\n",
    "for k in range(1,num_splits):  \n",
    "    spectra_to_species = pd.concat([spectra_to_species,locals()['spectra_to_species_{}'.format(k)]],axis=0)\n",
    "\n",
    "print(len(spectra_to_species))\n",
    "spectra_to_species.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of 7003 entries in spectra_to_species 3280 have duplicates.\n"
     ]
    }
   ],
   "source": [
    "# each df of path to spectra and Bruker DB should have overall unique entries\n",
    "assert ~any(spectra_to_species.duplicated(keep=False))\n",
    "\n",
    "# how many ['LaborID','Organism_best_match'] duplicates occur \n",
    "x = list(spectra_to_species.reset_index(level=['LaborID']).duplicated(subset=['LaborID','Organism_best_match'], keep=False))\n",
    "print('Of {} entries in spectra_to_species {} have duplicates.'.format(len(spectra_to_species),sum(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "A lot of spectra/samples are duplicated. This seems to occur due to repeated measurements of the same bacterial colony i.e. 4 consecutive well position numbers.\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) preprocess lab results, filter and convert to one-line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-36-98f29ee17f38>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-98f29ee17f38>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    print len(lab_results)\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "lab_results = pd.read_csv(PATH_FILE_lab_file)\n",
    "\n",
    "# drop column with RSI legend\n",
    "lab_results = lab_results.iloc[:,:12]\n",
    "lab_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_results_samples = lab_results.iloc[:,[1,2,3,6,7,8,9]]\n",
    "lab_results_samples = lab_results_samples.drop_duplicates()\n",
    "print('Number of lab results entries {}'.format(len(lab_results_samples)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lab_results)):\n",
    "    lab_results.iat[i,8] = lab_results.iat[i,8].strip(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count (LaborID, Keim) that are not unique, while keep multiplied lines for several antibiotics in mind\n",
    "lab_results_trunc = lab_results.iloc[:,[0,8,9]]\n",
    "print('Number of lines in lab_results that have a duplicate entry: {}'.format(sum(lab_results_trunc.duplicated(keep=False))))\n",
    "\n",
    "# remove these duplicated lines\n",
    "lab_results = lab_results.loc[~lab_results_trunc.duplicated(keep=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "All entries in lab_results are now unique to Lab ID and species. All lines with same Lab ID and species are due to different antibiotics.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make df of all occuring (LaborID, Keim) combinations\n",
    "LaborID_Keim_combinations = lab_results.drop_duplicates(subset=('Labor-ID','Keim')).drop(columns=lab_results.columns[[1,2,3,4,5,6,7,9,10,11]]).reset_index(drop=True)\n",
    "assert len(LaborID_Keim_combinations.drop_duplicates())==len(LaborID_Keim_combinations)\n",
    "\n",
    "# make list of all occuring antibiotics\n",
    "list_antibiotics = list(lab_results['Antibiotikum'].unique())\n",
    "\n",
    "# ----\n",
    "# rephrase lab_results to a one-line-per-sample version\n",
    "# ----\n",
    "\n",
    "# intialize df\n",
    "lab_results_oneline = pd.DataFrame(columns=['Labor-ID','Auftraggeb.-ID','Auftraggeber',\n",
    "                      'Geburtsdatum','Geschlecht','Mat-ID',\n",
    "                      'Material','Status','Keim']+list_antibiotics)\n",
    "\n",
    "for row in LaborID_Keim_combinations.itertuples():\n",
    "    current_labID = row[1]\n",
    "    current_spec = row[2]\n",
    "    \n",
    "    # find all lines with this LabID and Keim\n",
    "    current_subset = lab_results.loc[lab_results['Labor-ID'] == current_labID].loc[lab_results['Keim'] == current_spec]\n",
    "    current_antibiotics = list(current_subset['Antibiotikum'])\n",
    "    \n",
    "    oneline_subset = current_subset.iloc[:,:9].drop_duplicates() \n",
    "    assert len(oneline_subset)==1, 'Duplicates present in the subset. {}'.format(oneline_subset)\n",
    "    \n",
    "    # add column for each antiobiotic\n",
    "    for ab in list_antibiotics:\n",
    "        \n",
    "        # fill column entry with RSI values if it meets requirements, else empty\n",
    "        if ab in current_antibiotics:\n",
    "        \n",
    "            rsi_value = current_subset.loc[current_subset['Antibiotikum']==ab]['Sensibilitaet'].values[0]\n",
    "            \n",
    "            if rsi_value in [0]:\n",
    "                oneline_subset[ab] = 'S'\n",
    "            elif rsi_value in [1]:\n",
    "                oneline_subset[ab] = 'I'\n",
    "            elif rsi_value in [2]:\n",
    "                oneline_subset[ab] = 'R'\n",
    "            else:\n",
    "                oneline_subset[ab] = ''\n",
    "        else:\n",
    "            oneline_subset[ab] = ''\n",
    "\n",
    "    lab_results_oneline = pd.concat([lab_results_oneline,oneline_subset])\n",
    "print('number of labfile entries {} (with one entry per sample)'.format(len(lab_results_oneline)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if column is completely empty, delete column\n",
    "\n",
    "len_before = len(lab_results_oneline)\n",
    "\n",
    "for ab in list_antibiotics: \n",
    "    if all(lab_results_oneline[ab].unique() == ''):\n",
    "        lab_results_oneline.drop(columns=ab, inplace=True)\n",
    "\n",
    "\n",
    "print('number of excluded samples: {}'.format(len_before - len(lab_results_oneline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) match that with lab results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess tables to have the same datatypes\n",
    "spectra_to_species = spectra_to_species.reset_index(level=['LaborID'])\n",
    "lab_results_oneline['Labor-ID'] = lab_results_oneline['Labor-ID'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(spectra_to_species))\n",
    "print(len(lab_results_oneline))\n",
    "spectra_to_species_to_AMR = pd.merge(spectra_to_species, lab_results_oneline, \n",
    "                                        how='left', \n",
    "                                        left_on=['LaborID','Organism_best_match'], \n",
    "                                        right_on=['Labor-ID','Keim'])\n",
    "print(spectra_to_species_to_AMR.head())\n",
    "print(len(spectra_to_species_to_AMR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "Several lab could not be matched to spectra results file. Reasons identified were different species for the same Lab ID in the lab result file. \n",
    "\n",
    "This includes cases of Shigella in the lab file, that were labeled E.Coli by Bruker. Also Staph.aureus by Bruker that were labeled as MRSA Staph.aureus in the lab results file.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse entries without match\n",
    "print len(spectra_to_species)\n",
    "print len(lab_results_oneline) - len(spectra_to_species)\n",
    "\n",
    "no_matches = spectra_to_species_to_AMR.loc[spectra_to_species_to_AMR['Amoxicillin-Clavulan'].isnull()].iloc[:,:7]\n",
    "print(no_matches)\n",
    "\n",
    "mismatching_species = pd.merge(no_matches, lab_results_oneline, \n",
    "                                how='left', \n",
    "                                left_on=['LaborID'], \n",
    "                    #             right_on=['Labor-ID']).iloc[:,[0,6,7,15]]\n",
    "                                right_on=['Labor-ID']).iloc[:,[6,15]]\n",
    "print mismatching_species.Keim.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Nans - no matching LaborID/species in lab results\n",
    "print '{} entries in spectra_to_species_to_AMR could not be matched to lab results.'.format(sum(spectra_to_species_to_AMR['Minocyclin'].isnull()))\n",
    "\n",
    "# mismatched (any antibiotic can be used, it would be ' ' if it wasn't present in lab_results_oneline)\n",
    "spectra_to_species_to_AMR = spectra_to_species_to_AMR.loc[~spectra_to_species_to_AMR['Amoxicillin-Clavulan'].isnull()]\n",
    "\n",
    "spectra_to_species_to_AMR = spectra_to_species_to_AMR.sort_values(by=['LaborID','Datum_Kuerzel','Position'])\n",
    "\n",
    "# check for cases where duplicate LaborID/species entries cannot be explained by replicate measurements, \n",
    "# i.e. where the well position numbers are not consecutive\n",
    "x = list(spectra_to_species_to_AMR.duplicated(subset=['LaborID','Organism_best_match'], keep=False))\n",
    "# print spectra_to_species_to_AMR.loc[x]\n",
    "\n",
    "count_reps = spectra_to_species_to_AMR[['LaborID','Datum_Kuerzel','Organism_best_match','Position']].groupby(['LaborID','Datum_Kuerzel','Organism_best_match']).agg(['count'])\n",
    "print count_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove lines where [LaborID, Position] is not unique (very few cases)\n",
    "print len(spectra_to_species_to_AMR)\n",
    "spectra_to_species_to_AMR = spectra_to_species_to_AMR.loc[~spectra_to_species_to_AMR.duplicated(subset=['LaborID','Position'], keep=False)]\n",
    "print len(spectra_to_species_to_AMR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_to_species_to_AMR.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Export table to Aarau_converted.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Aarau antibiotic naming to USB antibiotic naming\n",
    "ab_matching = pd.read_csv(PATH_FILE_ab_matching).loc[:,['USB','Aarau']]\n",
    "ab_dict = get_antibiotics_name_matching(match_from='Aarau', match_to='USB')\n",
    "\n",
    "column_names = list(spectra_to_species_to_AMR.columns)\n",
    "assert id(column_names)!= id(spectra_to_species_to_AMR.columns)\n",
    "\n",
    "\n",
    "# make list of antibiotics that accour in the column headers spectra_to_species_to_AMR\n",
    "for col in list(spectra_to_species_to_AMR.columns):\n",
    "    if col not in list_antibiotics:\n",
    "        column_names.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to export format\n",
    "Aarau_converted = pd.DataFrame(columns=['species','code']+column_names)\n",
    "\n",
    "Aarau_converted['species'] = spectra_to_species_to_AMR['Organism_best_match']\n",
    "Aarau_converted['code'] = spectra_to_species_to_AMR[['LaborID', 'Position']].astype('str').apply(''.join, axis=1)\n",
    "\n",
    "for col in column_names:\n",
    "    Aarau_converted[col] = spectra_to_species_to_AMR[col]\n",
    "print Aarau_converted.head()\n",
    "\n",
    "# replace each antibiotic column header with the USB equivalent\n",
    "for col in column_names:\n",
    "    idx_col = np.where(Aarau_converted.columns==col)[0][0]\n",
    "    Aarau_converted.rename(columns={col:ab_dict[col]}, inplace=True)\n",
    "\n",
    "Aarau_converted.head()\n",
    "\n",
    "# export Aarau phenotype file\n",
    "Aarau_converted.to_csv(OUTPUT_FILE, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
