{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------\n",
    "# Cleaning of DRIAMS-B id file\n",
    "#\n",
    "# May 2018 C. Weis\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict as ddict\n",
    "from amr_maldi_ml.utilities import ab_name_map\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_IDRES_table = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Convert Validation dataset csv files into established format of Maldi project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'code', 'species', 'laboratory_species', 'Penicillin',\n",
      "       'Ceftriaxone', 'Vancomycin', 'Piperacillin-Tazobactam', 'Ciprofloxacin',\n",
      "       'Cefepime', 'Cotrimoxazol', 'Meropenem', 'Moxifloxacin',\n",
      "       'Amoxicillin-Clavulanic acid', 'Colistin', 'Tobramycin', 'Ceftazidime',\n",
      "       'Ceftolozane-Tazobactam', 'Ceftazidime-Avibactam', 'Ceftobiprole',\n",
      "       'Quinolones', 'Ceftazidime.1', 'Tigecycline', 'Levofloxacin',\n",
      "       'Fosfomycin', 'Amikacin', 'Imipenem', 'Minocycline', 'Gentamicin',\n",
      "       'Ceftarolin', 'Ampicillin-Sulbactam', 'Gentamicin_high_level',\n",
      "       'Aztreonam', 'Clindamycin', 'Ampicillin-Amoxicillin', 'Metronidazole',\n",
      "       'Daptomycin', 'Ampicillin-Amoxicillin.1', 'Caspofungin', 'Voriconazole',\n",
      "       'Posaconazole', 'Amphotericin B', 'Itraconazole', 'Fluconazole',\n",
      "       'Erythromycin', 'Doxycycline', 'Isavuconazole', 'Anidulafungin',\n",
      "       '5-Fluorocytosine', 'Micafungin', 'Cefepime.1', 'Tetracycline',\n",
      "       'Azithromycin', 'Ertapenem', 'Fosfomycin.1', 'Norfloxacin',\n",
      "       'Cefpodoxime', 'Nitrofurantoin', 'Aminoglycosides', 'Chloramphenicol',\n",
      "       'Rifampicin_1mg-l', 'Rifampicin', 'Linezolid',\n",
      "       'Amoxicillin-Clavulanic acid_uncomplicated_HWI',\n",
      "       'Strepomycin_high_level', 'Teicoplanin', 'Cefuroxime',\n",
      "       'Penicillin_with_endokarditis', 'Penicillin_without_endokarditis',\n",
      "       'Meropenem_with_meningitis', 'Meropenem_without_meningitis',\n",
      "       'Cefazolin', 'Oxacillin', 'Fusidic acid', 'Streptomycin',\n",
      "       'Isoniazid_.1mg-l', 'Pyrazinamide', 'Ethambutol_5mg-l', 'Cefixime',\n",
      "       'Mupirocin', 'Vancomycin.1', 'Teicoplanin.1', 'Cefoxitin_screen',\n",
      "       'Penicillin_with_meningitis', 'Clarithromycin',\n",
      "       'Penicillin_with_other_infections', 'Penicillin_with_pneumonia',\n",
      "       'Meropenem_with_pneumonia'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/links/groups/borgwardt/Data/DRIAMS/DRIAMS-A/id/2018/2018_clean.csv')\n",
    "USB_antibiotic_list = df.columns\n",
    "print(USB_antibiotic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_file = '/links/groups/borgwardt/Projects/maldi_tof_diagnostics/amr_maldi_ml/codeAC/KSBL/KSBL_res_report.csv'\n",
    "OUTPUT_file = '/links/groups/borgwardt/Data/DRIAMS/DRIAMS-B/id/2018/2018_clean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO change name matching to general script, not from AB-matching.csv\n",
    "# def get_antibiotics_name_matching(match_from='LIESTAL', match_to='USB'):\n",
    "#     assert match_from in ['LIESTAL','USB','Viollier','Aarau','Madrid']\n",
    "#     assert match_to in ['LIESTAL','USB','Viollier','Aarau','Madrid']\n",
    "#     csvname = '/links/groups/borgwardt/Projects/maldi_tof_diagnostics/amr_maldi_ml/MaldiML/MaldiML/files/AB-matching.csv'\n",
    "\n",
    "#     with open(csvname,'r', encoding='mac_roman') as f:\n",
    "#         ff = csv.reader(f, delimiter=',', dialect=csv.excel)\n",
    "#         list_antibiotics = []\n",
    "\n",
    "#         d_naming = ddict(list)\n",
    "\n",
    "#         for j, row in enumerate(ff):\n",
    "\n",
    "#             if j==0:\n",
    "#                 inidx = row.index(match_from)\n",
    "#                 outidx = row.index(match_to)\n",
    "#             else:\n",
    "#                 inname = row[inidx]\n",
    "#                 outname = row[outidx]\n",
    "#                 if inname == '':\n",
    "#                     continue\n",
    "#                 else:\n",
    "#                     d_naming[inname] = outname\n",
    "#     return d_naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_matching = get_antibiotics_name_matching(match_from='LIESTAL', match_to='USB')\n",
    "# d_matching['Cefuroxim oral'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# d_matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kantonsspital Basel-Land KSBL\n",
    "\n",
    "Every antibiotic resistance is its only line, so one spectra has multiple lines in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cefepime', 'Norfloxacin', 'Teicoplanin', 'Mupirocin', 'Imipenem', 'Linezolid', 'Cefuroxime', 'Amoxicillin-Clavulanic acid', 'Ertapenem', 'Levofloxacin', 'Clarithromycin', 'Amikacin', 'Nitrofurantoin', 'Rifampicin', 'Fosfomycin', 'Clindamycin', 'Tetracycline', 'Strepomycin_high_level', 'Meropenem', 'Erythromycin', 'Ampicillin-Amoxicillin', 'Piperacillin-Tazobactam', 'Oxacillin', 'Minocycline', 'Metronidazole', 'Daptomycin', 'Cotrimoxazol', 'Gentamicin', 'Vancomycin', 'Ceftazidime', 'Ciprofloxacin', 'Gentamicin_high_level', 'Tigecycline', 'Fusidic acid', 'Cefoxitin_screen', 'Ceftriaxone'}\n"
     ]
    }
   ],
   "source": [
    "# make antibiotics inventory first\n",
    "\n",
    "with open(INPUT_file,'r') as f:\n",
    "    ff = csv.reader(f, delimiter=';', dialect=csv.excel)\n",
    "    list_antibiotics = []\n",
    "    \n",
    "    for j, row in enumerate(ff):\n",
    "        if j==0:\n",
    "            header = list(row)\n",
    "            idx_antibiotic = header.index('Antibiotic')\n",
    "        else:\n",
    "            if row[idx_antibiotic] in ab_name_map.keys():\n",
    "                list_antibiotics.append(ab_name_map[row[idx_antibiotic]])\n",
    "\n",
    "list_antibiotics_KSBL = np.unique(list_antibiotics)\n",
    "\n",
    "union_USB_KSBL = set(USB_antibiotic_list) & set(list_antibiotics_KSBL)\n",
    "print(union_USB_KSBL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of BrukerIDs that are unique w.r.t. spectra scores, and strain from lab results\n",
    "#\n",
    "# this list is used by convert_csv function to subset the spectra that will be considered\n",
    "#\n",
    "with open(INPUT_file,'r') as f:\n",
    "    ff = csv.reader(f, delimiter=';', dialect=csv.excel)\n",
    "    \n",
    "    d = ddict(list)\n",
    "    for j, row in enumerate(ff):\n",
    "        if j==0:\n",
    "            header = list(row)\n",
    "            idx_Tagnr = header.index('Auftrag')\n",
    "            idx_Bruker = header.index('Bruker')\n",
    "            idx_species = header.index('Keim')\n",
    "            idx_score1 = header.index('Score1')\n",
    "        else:\n",
    "            d[row[idx_Bruker]].append(row[idx_Tagnr])\n",
    "            d[row[idx_Bruker]].append(row[idx_species])\n",
    "            d[row[idx_Bruker]].append(row[idx_score1])\n",
    "\n",
    "list_sampleID_unique = [key for key in d.keys() if len(np.unique(d[key]))==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in csv file\n",
    "def convert_csv(csvname, list_sampleIDs, list_antibiotics, d_ab_match, id_colname='Bruker', ab_colname='Antibiotic', rsi_colname='Resultat', species_colname='Organism_best_match' , genus_colname='GENUS'):\n",
    "    with open(csvname,'r') as f:\n",
    "        ff = csv.reader(f, delimiter=';', dialect=csv.excel)\n",
    "\n",
    "        currentBrukerID = ''\n",
    "        completeDataset_dict = ddict(list)\n",
    "\n",
    "        # initialize all antibiotics\n",
    "        for k in ['species', 'genus', 'code']:\n",
    "            completeDataset_dict[k].append('')\n",
    "        for ab in list_antibiotics:\n",
    "            completeDataset_dict[ab].append('')\n",
    "\n",
    "        for j, row in enumerate(ff):\n",
    "\n",
    "            if j==0:\n",
    "                header = list(row)\n",
    "                \n",
    "                idx_Bruker = header.index(id_colname)\n",
    "                idx_antibiotic = header.index(ab_colname)\n",
    "                idx_RSI = header.index(rsi_colname)\n",
    "\n",
    "                idx_species = header.index(species_colname)\n",
    "                idx_genus = header.index(genus_colname)\n",
    "\n",
    "            else:\n",
    "                BrukerID = list(row)[idx_Bruker]\n",
    "\n",
    "                if BrukerID not in list_sampleIDs:\n",
    "                    continue\n",
    "\n",
    "                # if sample exists, continue appending\n",
    "                elif BrukerID == currentBrukerID:\n",
    "                    if row[idx_antibiotic] in d_ab_match.keys():\n",
    "                        if d_ab_match[row[idx_antibiotic]] in list_antibiotics:\n",
    "                            completeDataset_dict[d_ab_match[row[idx_antibiotic]]].append(row[idx_RSI])\n",
    "\n",
    "                    assert currentSpecies == row[idx_species]\n",
    "                    assert currentGenus == row[idx_genus]\n",
    "\n",
    "                # start new sample\n",
    "                else:\n",
    "                    if j>1:\n",
    "                        # save sample before starting with a new one\n",
    "                        completeDataset_dict['code'].append(currentBrukerID)\n",
    "                        completeDataset_dict['genus'].append(currentGenus)\n",
    "                        completeDataset_dict['species'].append(currentSpecies)\n",
    "\n",
    "                        for ab in list_antibiotics:\n",
    "                            if len(completeDataset_dict[ab]) < len(completeDataset_dict['species']):\n",
    "                                completeDataset_dict[ab].append('nan')\n",
    "                        \n",
    "                        # each value (e.g. each column in our dataframe) has the same length\n",
    "                        x = [len(value) for key, value in completeDataset_dict.items()]\n",
    "                        print(completeDataset_dict)\n",
    "                        print(np.unique(x))\n",
    "                        assert len(np.unique(x)) == 1\n",
    "\n",
    "                    # start new sample\n",
    "                    currentBrukerID = BrukerID\n",
    "                    currentSpecies = row[idx_species]\n",
    "                    currentGenus = row[idx_genus]\n",
    "\n",
    "                    # start appending antibiotics resistances\n",
    "                    if row[idx_antibiotic] in d_ab_match.keys():\n",
    "                        if d_ab_match[row[idx_antibiotic]] in list_antibiotics:\n",
    "                            completeDataset_dict[d_ab_match[row[idx_antibiotic]]].append(row[idx_RSI])\n",
    "\n",
    "\n",
    "    # finish last sample\n",
    "    completeDataset_dict['code'].append(currentBrukerID)\n",
    "    completeDataset_dict['genus'].append(currentGenus)\n",
    "    completeDataset_dict['species'].append(currentSpecies)\n",
    "\n",
    "    for ab in list_antibiotics:\n",
    "        if len(completeDataset_dict[ab]) < len(completeDataset_dict['species']):\n",
    "            completeDataset_dict[ab].append('nan')\n",
    "\n",
    "    # each value (e.g. each column in our dataframe) has the same length\n",
    "    x = [len(value) for key, value in completeDataset_dict.items()]\n",
    "    print(np.unique(x))\n",
    "    assert len(np.unique(x)) == 1\n",
    "\n",
    "    KSBL_Dataset = pd.DataFrame.from_dict(completeDataset_dict)\n",
    "    \n",
    "    # clean up dataframe\n",
    "    KSBL_Dataset = KSBL_Dataset.drop(columns=['genus'])\n",
    "    KSBL_Dataset = KSBL_Dataset.replace({'RES': 'R', 'INT': 'I','negativ': '0', 'positiv': '1'})\n",
    "    #remove initialization line\n",
    "    KSBL_Dataset.drop(KSBL_Dataset.index[0], inplace=True) \n",
    "    \n",
    "    # assert only entries in ['0', '1', 'I', 'R', 'S', 'nan']\n",
    "    unique_vals = np.unique(KSBL_Dataset[list(KSBL_Dataset.drop(columns=['code','species']).columns)].values)\n",
    "    assert np.all([val in ['0', '1', 'I', 'R', 'S', 'nan'] for val in unique_vals])\n",
    "    \n",
    "    return KSBL_Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-33ef66c5ccf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# save table to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mKSBL_Dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_sampleID_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munion_USB_KSBL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mab_name_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecies_colname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Organism_best_match'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msave_IDRES_table\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mKSBL_Dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-d506b8082a7f>\u001b[0m in \u001b[0;36mconvert_csv\u001b[0;34m(csvname, list_sampleIDs, list_antibiotics, d_ab_match, id_colname, ab_colname, rsi_colname, species_colname, genus_colname)\u001b[0m\n\u001b[1;32m     55\u001b[0m                         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompleteDataset_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0;31m# start new sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# save table to file\n",
    "KSBL_Dataset = convert_csv(INPUT_file, list_sampleID_unique, union_USB_KSBL, ab_name_map, species_colname='Organism_best_match')\n",
    "\n",
    "if save_IDRES_table:\n",
    "    KSBL_Dataset.to_csv(OUTPUT_file, sep=',', encoding='utf-8', index=False)\n",
    "else:\n",
    "    print(KSBL_Dataset.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
