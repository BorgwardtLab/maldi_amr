{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## 2017\n",
    "\n",
    "# Load packages\n",
    "import json\n",
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "## Define paths\n",
    "# Path to MALDI spectra\n",
    "PATH_to_spectra_MALDI1 = '/Users/aline/MALDI-TOF-Machine_learning/01_Rawdata/01_Spectra/USBS/2017/2017/2017_01-12_monthly-added_not_renamed/'\n",
    "PATH_to_spectra_MALDI2 = '/Users/aline/MALDI-TOF-Machine_learning/01_Rawdata/01_Spectra/USBS/2017/2017/2017_m2/'\n",
    "\n",
    "#Path to Bruker reports\n",
    "PATH_to_Bruker_reports_17 = '/Users/aline/MALDI-TOF-Machine_learning/USB/2017/Bruker_reports/'\n",
    "\n",
    "# Path to the file extracted from the USB laboratory information system containing the AMR profiles acquired in routine diagnostics\n",
    "PATH_TO_IDRES_MLAB = '/Users/aline/MALDI-TOF-Machine_learning/USB/2017/ID_RES_2017-2.csv'\n",
    "\n",
    "#Path to the output file\n",
    "PATH_TO_Output = '/Users/aline/MALDI-TOF-Machine_learning/USB/2017/2017-01-12_IDRES_AB_not_summarised.csv'\n",
    "\n",
    "# make dicts, translating from Bruker encoding to TGNR for MALDI 1\n",
    "# read json files from, which are by default in the same directory as rawspectra\n",
    "# read two variables in dictonary: (i) TGNR (= laboratory ID assigned in clinical routine) and (ii) Brukercode: coode assigned during the spectra acquisition. \n",
    "\n",
    "### MALDI 1\n",
    "return_list_1 = []\n",
    "runinfo_all_1 = []\n",
    "\n",
    "for root, dirs, files in os.walk(PATH_to_spectra_MALDI1):\n",
    "    for name in files:\n",
    "        if name.startswith((\"info\")):\n",
    "            with open(os.path.join(root, name)) as json_file:\n",
    "                runinfo_all_1.append(json.load(json_file))\n",
    "\n",
    "dicts_1 = []\n",
    "dicts_all = []\n",
    "for runinfo in runinfo_all_1: \n",
    "        dicts_1.append({runinfo['AnalyteUid']:runinfo['AnalyteId']})\n",
    "dicts_all = {}\n",
    "for d in dicts_1:\n",
    "    dicts_all.update(d)\n",
    "\n",
    "#Add string to code, to make it unambiguous, wehn combining MALDI1 and MALDI2\n",
    "dicts_all_17_1 = dict((\"{}{}\".format(k,'_MALDI1'),v) for k,v in dicts_all.items())\n",
    "\n",
    "\n",
    "### MALDI 2 \n",
    "# make dicts, translating from Bruker encoding to TGNR for MALDI 1\n",
    "return_list_1 = []\n",
    "runinfo_all_1 = []\n",
    "\n",
    "for root, dirs, files in os.walk(PATH_to_spectra_MALDI2):\n",
    "    for name in files:\n",
    "        if name.startswith((\"info\")):\n",
    "            with open(os.path.join(root, name)) as json_file:\n",
    "                runinfo_all_1.append(json.load(json_file))\n",
    "dicts_1 = []\n",
    "dicts_all_1= []\n",
    "for runinfo in runinfo_all_1: \n",
    "        dicts_1.append({runinfo['AnalyteUid']:runinfo['AnalyteId']})\n",
    "dicts_all_1 = {}\n",
    "for d in dicts_1:\n",
    "    dicts_all_1.update(d)\n",
    "\n",
    "#Add string to code, to make it unambiguous, wehn combining MALDI1 and MALDI2\n",
    "dicts_all_17_2 = dict((\"{}{}\".format(k,'_MALDI2'),v) for k,v in dicts_all_1.items())\n",
    "\n",
    "#Combine dicts from MALDI1 and MALDI2\n",
    "dicts_all = {}\n",
    "dicts_all = {**dicts_all_17_1, **dicts_all_17_2}\n",
    "\n",
    "# Save dictionary as dataframe and add 'year' column\n",
    "dicts_17_df = pd.DataFrame(dicts_all, index=[0]).transpose()\n",
    "dicts_17_df['YEAR'] = '2017'\n",
    "\n",
    "dicts_all_df = dicts_17_df\n",
    "\n",
    "# rename columns and drop duplicates\n",
    "dicts_all_df.index.name = 'code'\n",
    "dicts_all_df.reset_index(inplace=True)\n",
    "dicts_all_df.columns=['code', 'strain', 'YEAR']\n",
    "\n",
    "\n",
    "# Read Bruker reports. These contain the microbial species identification per spectra, which was assigned by comparing each spectra to the Biotyper Database v.8.0.\n",
    "# MALDI 1\n",
    "report_12 = pd.read_csv(os.path.join(PATH_to_Bruker_reports_17, '2017_12.csv'), error_bad_lines=False, sep=',', header=None)\n",
    "report_11_1 = pd.read_csv(os.path.join(PATH_to_Bruker_reports_17, '2017_10-11-1.csv'), error_bad_lines=False, sep=',', header=None)\n",
    "report_11_2 = pd.read_csv(os.path.join(PATH_to_Bruker_reports_17, '2017_10-11-2.csv'), error_bad_lines=False, sep=',', header=None)\n",
    "report_09 = pd.read_csv(os.path.join(PATH_to_Bruker_reports_17, '2017_09.csv'), error_bad_lines=False, sep=',', header=None)\n",
    "report_08 = pd.read_csv(os.path.join(PATH_to_Bruker_reports_17, '2017_08.csv'), error_bad_lines=False, sep=',', header=None)\n",
    "report_07 = pd.read_csv(os.path.join(PATH_to_Bruker_reports_17, '2017_07.csv'), error_bad_lines=False, sep=',', header=None)\n",
    "report_06 = pd.read_csv(os.path.join(PATH_to_Bruker_reports_17, '2017_06.csv'), error_bad_lines=False, sep=',', header=None)\n",
    "report_05 = pd.read_csv(os.path.join(PATH_to_Bruker_reports_17, '2017_05.csv'), error_bad_lines=False, sep=',', header=None)\n",
    "report_04 = pd.read_csv(os.path.join(PATH_to_Bruker_reports_17, '2017_04.csv'), error_bad_lines=False, sep=',', header=None)\n",
    "report_03 = pd.read_csv(os.path.join(PATH_to_Bruker_reports_17, '2017_03.csv'), error_bad_lines=False, sep=',', header=None)\n",
    "report_02 = pd.read_csv(os.path.join(PATH_to_Bruker_reports_17, '2017_02.csv'), error_bad_lines=False, sep=',', header=None)\n",
    "report_01 = pd.read_csv(os.path.join(PATH_to_Bruker_reports_17, '2017_01.csv'), error_bad_lines=False, sep=',', header=None)\n",
    "\n",
    "# Combine the reports from all months and rename columns\n",
    "report=pd.DataFrame()\n",
    "report=report_12.append(report_11_1)\n",
    "report=report.append(report_11_2)\n",
    "report=report.append(report_09)\n",
    "report=report.append(report_08)\n",
    "report=report.append(report_07)\n",
    "report=report.append(report_06)\n",
    "report=report.append(report_05)\n",
    "report=report.append(report_04)\n",
    "report=report.append(report_03)\n",
    "report=report.append(report_02)\n",
    "report=report.append(report_01)\n",
    "\n",
    "report_m1 = report\n",
    "\n",
    "#Rename columns\n",
    "report_m1.columns = ['Brukername', 'Value','A','Organism_best_match', 'Score1', 'Organism(second best match)', 'Score2']\n",
    "\n",
    "# Add '_MALDI1' to make it unique before matching with reports from MALDI2\n",
    "report_m1['code'] = [row if re.match(r'\\w{8}\\-\\w{4}\\-\\w{4}-\\w{4}-\\w{12}', row) else 'NA' for row in report_m1['Brukername']]  \n",
    "report_m1['code'] = [row + '_MALDI1' if not re.match('NA', row) else 'NA' for row in report_m1['code']]\n",
    "\n",
    "# Remove the rows which contain 'not (yet) present' as identification, they have been reanalised \n",
    "report_m1 = report_m1.drop(report_m1.index[report_m1.Organism_best_match == 'not (yet) present'])\n",
    "\n",
    "#drop duplicated entries in case they have been multiple times in Brukeroutput\n",
    "report_m1 = report_m1.drop_duplicates()\n",
    "\n",
    "# MALDI2\n",
    "report_m2 = pd.read_csv(os.path.join(PATH_to_Bruker_reports_17, '2017_MALDI2.csv'), error_bad_lines=False, sep=';', header=None)\n",
    "\n",
    "#Drop 8th column as it is empty\n",
    "report_m2 = report_m2.drop(report_m2.columns[7], axis=1)\n",
    "\n",
    "#Rename columns\n",
    "report_m2.columns = ['Brukername', 'Value','A','Organism_best_match', 'Score1', 'Organism(second best match)', 'Score2']\n",
    "\n",
    "# Add '_MALDI1' to make it unique before matching with reports from MALDI2\n",
    "report_m2['code'] = [row if re.match(r'\\w{8}\\-\\w{4}\\-\\w{4}-\\w{4}-\\w{12}', row) else 'NA' for row in report_m2['Brukername']]  \n",
    "report_m2['code'] = [row + '_MALDI2' if not re.match('NA', row) else 'NA' for row in report_m2['code']]\n",
    "\n",
    "# Remove the rows which contain 'not (yet) present' as identification, they have been reanalised \n",
    "report_m2 = report_m2.drop(report_m2.index[report_m2.Organism_best_match == 'not (yet) present'])\n",
    "\n",
    "#drop duplicated entries in case they have been multiple times in Brukeroutput\n",
    "report_m2 = report_m2.drop_duplicates()\n",
    "\n",
    "# Concetenate reports from MALDI1 and MALDI2\n",
    "report = pd.concat([report_m1, report_m2])\n",
    "\n",
    "# Save 'code' as string and reset index\n",
    "report['code'] = report['code'].astype(str) \n",
    "report = report.reset_index(drop=True)\n",
    "\n",
    "# Extract 6-digit TGNR from strainname in order to match with the AMR profile acquired at USB\n",
    "dicts_all_df['TAGESNUMMER'] = [re.findall(r'\\d{6}', row) if re.match(r'\\d{6}', row) else 'NA' for row in dicts_all_df.strain]\n",
    "dicts_all_df['TAGESNUMMER'] = [match[0] for match in dicts_all_df.TAGESNUMMER]\n",
    "\n",
    "# Merge dicts_all_df with Bruker reports\n",
    "report_MALDI = pd.merge(dicts_all_df, report, on=['code'], how='outer')\n",
    "report_MALDI = report_MALDI.drop_duplicates()\n",
    "\n",
    "# Drop rows with empty TGNR \n",
    "report_MALDI.TAGESNUMMER.fillna('', inplace= True)\n",
    "report_MALDI= report_MALDI[report_MALDI.TAGESNUMMER.notnull()]\n",
    "\n",
    "# Add '2017' string to TGNR to make it unique before combining it with data from other years\n",
    "report_MALDI['TAGESNUMMER'] = '2017' + report_MALDI['TAGESNUMMER'].astype(str)  \n",
    "\n",
    "# Drop rows with empty TGNR\n",
    "report_MALDI = report_MALDI[-report_MALDI['TAGESNUMMER'].isin(['2017N'])]\n",
    "report_MALDI = report_MALDI.drop_duplicates()\n",
    "\n",
    "# Import AMR File, which was extracted from USB laboratory information system\n",
    "ID_RES = pd.DataFrame(pd.read_csv(PATH_TO_IDRES_MLAB, error_bad_lines=False, sep=';', low_memory=False))\n",
    "\n",
    "# Drop rows with 'NA' as TAGESNUMMER\n",
    "ID_RES['TAGESNUMMER'] = ID_RES['TAGESNUMMER'].astype(str)\n",
    "ID_RES = ID_RES[ID_RES['TAGESNUMMER'].str.contains(\"NA\")== False]\n",
    "\n",
    "# Add 'GENUS' column for matching\n",
    "ID_RES['GENUS'] = ID_RES['KEIM'].str.split('\\s').str[0]\n",
    "# Add 'SPEZIES_MLAB column\n",
    "ID_RES['SPEZIES_MLAB'] = ID_RES['KEIM'].str.split('\\s').str[1]\n",
    "cols = ID_RES.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "ID_RES = ID_RES[cols]\n",
    "ID_RES['SPEZIES_MLAB']=ID_RES['SPEZIES_MLAB'].str.replace('\\xa0',' ')\n",
    "\n",
    "# Add 'GENUS' column for matching\n",
    "report_MALDI['Organism_best_match']=report_MALDI['Organism_best_match'].str.strip(' ')\n",
    "# Add 'SPEZIES_MLAB colum\n",
    "report_MALDI['SPEZIES_MALDI'] = report_MALDI['Organism_best_match'].str.split('\\s').str[1]\n",
    "report_MALDI['GENUS'] = report_MALDI['Organism_best_match'].str.split('\\s').str[0]\n",
    "report_MALDI['GENUS_match'] = report_MALDI['GENUS'].str.replace('MIX!', '')\n",
    "\n",
    "# Merge with TGNR and GENUS in order to account for species differences between MLAB am MALDI\n",
    "result_IDRES = pd.merge(report_MALDI, ID_RES, left_on=['GENUS_match', 'TAGESNUMMER'], right_on=['GENUS', 'TAGESNUMMER'], how = 'left')\n",
    "result_IDRES = result_IDRES.drop(['GENUS_y', 'GENUS_match'], axis=1)\n",
    "result_IDRES.rename(columns={'GENUS_x':'GENUS'}, inplace=True)\n",
    "result_IDRES = result_IDRES.drop_duplicates()\n",
    "\n",
    "# Remove rows containing'not reliable identification', 'no peaks found' as species identification\n",
    "result_IDRES = result_IDRES[-result_IDRES['Organism_best_match'].isin(['not reliable identification', 'no peaks found'])]\n",
    "\n",
    "# Harmonize columnnames\n",
    "result_IDRES.columns = result_IDRES.columns.str.replace(\"ä\", \"ae\")\n",
    "result_IDRES.columns = result_IDRES.columns.str.replace(\"Amoxicillin...Clavulansaeure.bei.unkompliziertem.HWI\", \"Amoxicillin-Clavulansaeure.unkompl.HWI\")\n",
    "result_IDRES.columns = result_IDRES.columns.str.replace(\"Organism_best_match\", \"Organism(best match)\")\n",
    "\n",
    "#result_IDRES.drop('Brukername\"', axis=1, inplace=True)\n",
    "result_IDRES.drop('YEAR', axis=1, inplace=True)\n",
    "\n",
    "result_IDRES = result_IDRES[['code', 'strain', 'Value', 'A', 'Organism(best match)', 'Score1', 'Organism(second best match)', 'Score2', 'TAGESNUMMER', 'SPEZIES_MALDI', 'GENUS', 'SPEZIES_MLAB', 'MATERIAL', 'KEIM', 'AUFTRAGSNUMMER', 'STATION', 'PATIENTENNUMMER', 'GEBURTSDATUM', 'GESCHLECHT', 'EINGANGSDATUM', 'LOKALISATION', 'Ciprofloxacin', 'Cefepim', 'Meropenem', 'Piperacillin...Tazobactam', 'Cotrimoxazol', 'Ceftazidim', 'Levofloxacin', 'Colistin', 'Tobramycin', 'Ceftriaxon', 'Imipenem', 'Amikacin', 'Tigecyclin', 'Clindamycin', 'Amoxicillin...Clavulansaeure', 'Amoxicillin', 'Posaconazol', 'Itraconazol', 'Voriconazol', 'Caspofungin', 'Amphotericin.B', 'Penicillin', 'Vancomycin', 'Ertapenem', 'Metronidazol', 'Moxifloxacin', 'Rifampicin', 'Erythromycin', 'Fluconazol', 'Anidulafungin', 'X5.Fluorocytosin', 'Micafungin', 'Ampicillin...Amoxicillin', 'Norfloxacin', 'Fosfomycin.Trometamol', 'Cefpodoxim', 'Chloramphenicol', 'Aminoglykoside', 'Chinolone', 'Daptomycin', 'Teicoplanin', 'Linezolid', 'Gentamicin', 'Gentamicin.High.level', 'Nitrofurantoin', 'Cefuroxim', 'Meropenem.ohne.Meningitis', 'Meropenem.bei.Meningitis', 'Ceftazidim.1', 'Fosfomycin', 'Aztreonam', 'Cefazolin', 'Tetracyclin', 'Fusidinsaeure', 'Oxacillin', 'Clarithromycin', 'Isoniazid.0.1.mg.l', 'Streptomycin.1.0.mg.l', 'Rifampicin.1.0.mg.l', 'Ethambutol.5.0.mg.l', 'Pyrazinamid.100.0.mg.l', 'Azithromycin', 'Cefixim', 'Doxycyclin', 'Mupirocin', 'Vancomycin.GRD', 'Teicoplanin.GRD', 'Cefoxitin.Screen', 'Ceftarolin', 'Ticarcillin...Clavulansaeure', 'Penicillin.bei.Endokarditis', 'Penicillin.ohne.Meningitis', 'Penicillin.ohne.Endokarditis', 'Dummy', 'Penicillin.bei.Pneumonie', 'Penicillin.bei.anderen.Infekten', 'Penicillin.bei.Meningitis', 'Meropenem.bei.Pneumonie', 'Cefepim.1', 'Minocyclin', 'Cefuroxim.Axetil', 'Amoxicillin-Clavulansaeure.unkompl.HWI', 'Ceftazidim.Avibactam', 'Ceftolozan...Tazobactam', 'Ampicillin...Sulbactam', 'Ceftobiprol', 'Bacitracin', 'Isoniazid.0.4.mg.l', 'Streptomycin.High.level', 'Isavuconazol']]\n",
    "\n",
    "# Write out resulting dataframe\n",
    "result_IDRES = result_IDRES.replace(';',',')\n",
    "pd.DataFrame.to_csv(result_IDRES, PATH_TO_Output ,sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
